# Helm chart for the Indy-Monitoring-Stack

_**Work in progress, for development use only.**_

## Pre-requisites

*   K8s or minikube cluster
*   Helm v3+ binaries
*   Registered Indy network monitor seed

## Components

Prometheus and alertmanager are now optional and are disabled by default.  This is done to simplified the solution and to avoid having the same data in influxDB and in Prometheus.  It's done from the values.yaml file.

## Quickstart

### Configuring the deployment

1.  Clone and edit the [**extra_vars.template**](./extra_vars.template) to a file called **extra_vars.yaml**.
    
        cp extra_vars.template extra_vars.yaml

2.  Edit the inputs. For some reference you can look at the [**config/indy_node_monitor/networks.json**](./config/indy_node_monitor/networks.json) file. You can add as many as you want. You must include a registered network monitor seed for your selected networks.

    Here is an example for the soverin network:
    ```plaintext
    inputs:
      - name: Sovrin Builder Net
        short_name: sbn
        genesis_url: https://raw.githubusercontent.com/sovrin-foundation/sovrin/stable/sovrin/pool_transactions_builder_genesis
        network_monitor_seed: INSERT_REGISTERED_NETWORK_MONITOR_SEED_HERE
      - name: Sovrin Staging Net
        short_name: ssn
        genesis_url: https://raw.githubusercontent.com/sovrin-foundation/sovrin/stable/sovrin/pool_transactions_sandbox_genesis
        network_monitor_seed: INSERT_REGISTERED_NETWORK_MONITOR_SEED_HERE
      - name: Sovrin Main Net
        short_name: smn
        genesis_url: https://raw.githubusercontent.com/sovrin-foundation/sovrin/stable/sovrin/pool_transactions_live_genesis
        network_monitor_seed: INSERT_REGISTERED_NETWORK_MONITOR_SEED_HERE
    ```
3.  The secrets are generated by helm and are kept encode in k8s secret.

4.  (optional) If you want to expose services, set the **ingress** or **route** to `True`, enter your **domain** and **endpoints** (you can expose via ingress or via a route if this is more convenient).

5.  In order to get alerts for a specific blockchain, you must edit the provided alarm file **grafana/provisioning/alerting/indy-node-monitor.yaml**  and replace "Sovrin Builder Net" by your own Network Name.

### Deployment

Once you're happy with the configuration, create the project (for openshit) or namespace (for k8s) and deploy the stack. Here's a Openshift one liner that will take care of this for you. Make sure that the namespace name matches the one in **extra_vars.yaml** file.

```plaintext
oc new-project inc-indy-node-monitor
```

Here is the helm on liner to deploy the stack:

```plaintext
helm upgrade indy-monitoring-stack . \
    --namespace inc-indy-node-monitor \
    --values ./extra_vars.yaml \
    --create-namespace --install
```

This chart will deploy by default, 4 components that are, **indy-no-monitor**, **telegraf**, **influxdb**, **grafana**  
After the deployment you can get the Grafana admin password from this secret:

```plaintext
kubectl get secret credentials -n inc-indy-node-monitor -o jsonpath="{.data.GF_SECURITY_ADMIN_PASSWORD}" | base64 --decode; echo
```

Note: On some linux env the last **%** of the password is not part of the password.

## Advanced configuration

You can edit the ports for the applications but this is not recommended. Some ports are statically set in the configuration files and it might break things if you are not sure about what you are doing. It is recommeneded to keep the ports as they are defined in the [**values.yaml**](./values.yaml) file.

You can enable cloudwatch metric which will configure telegraf to send all metric to indy timeseries backend (influxDB or prometheus) and to AWS CLoudwatch.  For this to work all container must be set to UTC, if not you will get error that AWS refuse you metric because they are in the future if youre timezone is < GMT -2.

### Service configuration

All service configurations are located in the [**config/**](./config/) folder under their respective application directory. These configurations are loaded as configmaps during deployment and injected into the pods. 

You can apply a new configuration by editing these files and redeploying the stack.

### Dashboard development

You can export a dashboard from grafana after you customized it and add the ***.json** file generated under [**config/grafana/dashboards/**](./config/grafana/dashboards/)

All dashboards from that directory are automatically loaded when redeploying the stack.
